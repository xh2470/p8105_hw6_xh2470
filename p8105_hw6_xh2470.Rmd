---
title: "p8105_hw6_xh2470"
output: github_document
---

```{r set up}
library(tidyverse)
library(patchwork)
library(viridis)
library(modelr)
library(mgcv)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

 theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

# Problem 1

#### Load and clean the data.

```{r}
birthweight = 
  read_csv("./data/birthweight.csv") %>% 
  rename(head_circ = bhead,
         length = blength,
         birthweight = bwt,
         ges_age = gaweeks) %>% 
  mutate(sex = recode(babysex, `1` = "Male", `2` = "Female"))

```

#### Propose a regression model for birthweight.

```{r}
birthweight_lm = 
  birthweight %>%
  select(birthweight, head_circ, length) %>% 
  drop_na() 

fit = lm(birthweight ~ head_circ + length, data = birthweight_lm) 

fit %>% 
  broom::tidy() %>% 
  select(term, estimate, p.value) %>%
  mutate(term = str_replace(term, "head_circ", "Head Circumference"),
         term = str_replace(term, "length", "Length")) %>% 
  knitr::kable(digits = 3)
```

I hypothesize that baby's head circumference and length at birth would be important factors affecting the birth weight of babies. Thus, I process the above linear regression model. First, I select related variables `birthweight`, `head_circ`,and `length` from the original dataset, and drop missing values. Second, I make a linear regression model by using `birthweight` as the response and `head_circ` and `length` as predictors. Third, tidy the resutls and show it in a table.

#### Make a plot of model residuals against fitted values.

```{r}
modelr::add_residuals(birthweight_lm, fit) %>%
  modelr::add_predictions(fit) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point() +
  labs(
    title = "Residuals vs. Fitted Values",
    x = "Prediction",
    y = "Residuals"
  )
```

From the plot, we can see that among fitted values, residuals are distributed around 0.

#### Compare the above model to two others.

```{r}
birthweight_df =
  birthweight %>%
  select(birthweight, length, ges_age, head_circ, sex) %>% 
  crossv_mc(100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)) %>% 
   mutate(
    mod_1  = map(train, ~lm(birthweight ~ length + ges_age, data = .x)),
    mod_2  = map(train, ~lm(birthweight ~ head_circ + sex + length + head_circ * sex + length * sex + head_circ * length + head_circ * sex *length, data = .x)),
    birthweight_lm  = map(train, ~lm(birthweight ~ head_circ + length, data = .x))
    ) %>% 
  mutate(
    rmse_mod_1 = map2_dbl(mod_1, test, ~rmse(model = .x, data = .y)),
    rmse_mod_2 = map2_dbl(mod_2, test, ~rmse(model = .x, data = .y)),
    rmse_birthweight_lm = map2_dbl(birthweight_lm, test, ~rmse(model = .x, data = .y)))

birthweight_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() + 
  labs(
    title = "Comparision of three models",
    x = "Model",
    y = "RMSE",
    caption = "mod_1: using length at birth and gestational age as predictors
               mod_2: using head circumference, length, sex, and all interactions as predictors
               birthweight_lm : using head circumference and length as predictors"
  )
```

# Problem 2

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

#### Use 5000 bootstrap samples to produce estimates of quantities.

```{r}
boot_strap = 
  weather_df %>%
  bootstrap(n = 5000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(tmax ~ tmin, data = .x)),
    r_square = map(models, broom::glance),
    results = map(models, broom::tidy)
  ) %>% 
  select(strap_number, r_square, results) 

r_square = 
  boot_strap %>% 
  unnest(r_square) %>% 
  select(strap_number, r.squared)

r_square

intercept = 
  boot_strap %>% 
  unnest(results) %>%
  select(strap_number,term, estimate) %>% 
  mutate(
    term = recode(term, `(Intercept)` = "beta0_hat", `tmin` = "beta1_hat")
  ) %>% 
  pivot_wider(
    names_from = "term",
    values_from = "estimate"
  ) %>% 
  mutate(log = log(beta0_hat * beta1_hat))

intercept
```

#### Plot the distribution of estimates.

```{r}
r_square_plot = 
r_square %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() + 
  labs(
    title = "Estimates of r square",
    x = "r square",
    y = "Count"
  )

intercept_plot = 
intercept %>% 
  ggplot(aes(x = log)) +
  geom_density() + 
  labs(
    title = "Estimates of log(beta0 * beta1)",
    x = "log(beta0 * beta1)",
    y = "Count"
  )  

r_square_plot + intercept_plot

```

From the plots, we can see that the distribution of both estimates r square and log(beta0*beta1) are approximately normally distributed. The closer r square is to 1, the better the model fitting effect is. 

#### Provide 95% confidence interval for the estimates.

```{r}
r_square_ci = 
  r_square %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))  

r_square_ci

intercept_ci = 
  intercept %>% 
  summarize(
    ci_lower = quantile(log, 0.025), 
    ci_upper = quantile(log, 0.975))  

intercept_ci

```

The lower limit and upper limit of 95% confidence interval for r square is **`r round(pull(r_square_ci, ci_lower),digit = 3)`** and **`r round(pull(r_square_ci, ci_upper), digit = 3)`**, respectively. The lower limit and upper limit of 95% confidence interval for log(beta0 * beta1) is **`r round(pull(intercept_ci, ci_lower),digit = 2)`** and **`r round(pull(intercept_ci, ci_upper),digit = 2)`**, respectively. 
